# Guide de D√©ploiement - Service vLLM Medium (Qwen3-32B-AWQ)

**Derni√®re mise √† jour** : 2025-10-22  
**Version** : 1.0

## üìã Table des Mati√®res
1. [Pr√©requis Syst√®me](#1-pr√©requis-syst√®me)
2. [Configuration Environnement](#2-configuration-environnement)
3. [Validation Pr√©-D√©ploiement](#3-validation-pr√©-d√©ploiement)
4. [Proc√©dure de D√©ploiement](#4-proc√©dure-de-d√©ploiement)
5. [Monitoring Post-D√©ploiement](#5-monitoring-post-d√©ploiement)
6. [Troubleshooting D√©ploiement](#6-troubleshooting-d√©ploiement)
7. [Scripts de R√©f√©rence](#7-scripts-de-r√©f√©rence)

---

## 1. Pr√©requis Syst√®me

### Mat√©riel Requis

- **GPU** : 2√ó NVIDIA RTX 4090 (24GB VRAM chacune)
- **RAM** : Minimum 32GB recommand√©
- **Disque** : ~50GB disponible pour mod√®le + cache

### Logiciels Requis

- Docker Desktop avec support GPU (NVIDIA Container Toolkit)
- PowerShell 7+ (pour scripts automation)
- Git (pour gestion version)

### V√©rification GPU

```bash
# V√©rifier disponibilit√© 2√ó RTX 4090
nvidia-smi

# Tester GPU dans conteneur Docker
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

**Sortie attendue** : Liste des 2 GPUs avec m√©moire disponible

---

## 2. Configuration Environnement

### Fichier `.env`

Cr√©er [`myia_vllm/.env`](myia_vllm/.env) avec :

```bash
# API Keys (NE JAMAIS VERSIONNER)
VLLM_API_KEY_MEDIUM=<g√©n√©rer_cl√©_s√©curis√©e>

# GPU Configuration
CUDA_VISIBLE_DEVICES_MEDIUM=0,1

# Container Configuration
CONTAINER_NAME_MEDIUM=myia_vllm-medium-qwen3
```

**‚ö†Ô∏è S√âCURIT√â** : Fichier `.env` doit √™tre dans [`.gitignore`](myia_vllm/.gitignore)

**üìö Documentation compl√®te** : Voir [`setup/ENV_CONFIGURATION.md`](myia_vllm/docs/setup/ENV_CONFIGURATION.md)

### Configuration Docker Compose

Fichier principal : [`myia_vllm/configs/docker/profiles/medium.yml`](myia_vllm/configs/docker/profiles/medium.yml)

**Param√®tres critiques valid√©s (Configuration Optimale - Mission 15)** :

```yaml
services:
  medium-qwen3:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    ipc: host
    shm_size: '16gb'
    environment:
      - NVIDIA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES_MEDIUM:-0,1}
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    command:
      - "--model"
      - "Qwen/Qwen3-32B-AWQ"
      - "--gpu-memory-utilization"
      - "0.85"
      - "--enable-chunked-prefill"
      - "--tensor-parallel-size"
      - "2"
```

**Param√®tres cl√©s** :
- [`gpu-memory-utilization: 0.85`](myia_vllm/configs/docker/profiles/medium.yml) (vs 0.95 baseline) : Stabilit√© accrue
- [`enable-chunked-prefill: true`](myia_vllm/configs/docker/profiles/medium.yml) : Lissage utilisation m√©moire
- [`enable-prefix-caching: false`](myia_vllm/configs/docker/profiles/medium.yml) : Meilleures performances seul (d√©sactiv√©)
- [`tensor-parallel-size: 2`](myia_vllm/configs/docker/profiles/medium.yml) : 2√ó RTX 4090

**üìö Documentation architecture** : Voir [`docker/ARCHITECTURE.md`](myia_vllm/docs/docker/ARCHITECTURE.md)

---

## 3. Validation Pr√©-D√©ploiement

### Checklist S√©curit√©

Source : [`deployment/DEPLOYMENT_SAFETY.md`](myia_vllm/docs/deployment/DEPLOYMENT_SAFETY.md)

- [ ] Fichier `.env` cr√©√© et NON versionn√©
- [ ] Cl√© API g√©n√©r√©e (32+ caract√®res alphanum√©riques)
- [ ] GPUs d√©tect√©s (`nvidia-smi` r√©ussit)
- [ ] Docker Desktop lanc√© et fonctionnel
- [ ] Espace disque suffisant (~50GB libre)
- [ ] Aucun autre conteneur vLLM actif (`docker ps -a`)

### V√©rification Automatis√©e

Utiliser script : [`myia_vllm/scripts/check_ram_usage.ps1`](myia_vllm/scripts/check_ram_usage.ps1)

```powershell
# V√©rifier ressources syst√®me
pwsh -c ".\myia_vllm\scripts\check_ram_usage.ps1"
```

### Validation Configuration Docker

```bash
# Valider syntaxe YAML
docker compose -f myia_vllm/configs/docker/profiles/medium.yml config

# V√©rifier chargement variables .env
docker compose -p myia_vllm --env-file myia_vllm/.env \
  -f myia_vllm/configs/docker/profiles/medium.yml config | grep -i "api_key\|cuda"
```

---

## 4. Proc√©dure de D√©ploiement

### M√©thode 1 : D√©ploiement Automatis√© (RECOMMAND√â)

**Script** : [`myia_vllm/scripts/deploy_medium_monitored.ps1`](myia_vllm/scripts/deploy_medium_monitored.ps1)

```powershell
# Lancer d√©ploiement avec monitoring int√©gr√©
pwsh -c ".\myia_vllm\scripts\deploy_medium_monitored.ps1"
```

**Ce script effectue automatiquement :**
1. Nettoyage containers existants
2. Reconstruction image Docker (`--build --force-recreate`)
3. Lancement service en arri√®re-plan (`-d`)
4. Monitoring jusqu'√† √©tat `(healthy)`
5. Validation health check

**Dur√©e estim√©e** : 5-10 minutes (chargement mod√®le + initialisation)

### M√©thode 2 : D√©ploiement Manuel

**√âtape 1 : Nettoyage**
```powershell
cd myia_vllm
docker compose -p myia_vllm --env-file .env \
  -f configs/docker/docker-compose.yml \
  -f configs/docker/profiles/medium.yml \
  down --remove-orphans
```

**√âtape 2 : Lancement**
```powershell
docker compose -p myia_vllm --env-file .env \
  -f configs/docker/docker-compose.yml \
  -f configs/docker/profiles/medium.yml \
  up -d --build --force-recreate
```

**√âtape 3 : Monitoring**
```powershell
# Attendre √©tat (healthy) - Timeout 10 minutes
pwsh -c ".\scripts\monitoring\wait_for_container_healthy.ps1 -Timeout 600"
```

**üìö Script monitoring** : [`scripts/monitoring/wait_for_container_healthy.ps1`](myia_vllm/scripts/monitoring/wait_for_container_healthy.ps1)

---

## 5. Monitoring Post-D√©ploiement

### V√©rification √âtat Container

```powershell
# V√©rifier container actif
docker ps --filter "name=myia_vllm-medium-qwen3"

# Exemple output attendu :
# CONTAINER ID   STATUS                    PORTS
# abc123def456   Up 5 minutes (healthy)    0.0.0.0:8000->8000/tcp
```

### Health Check API

```bash
# Test endpoint sant√©
curl http://localhost:8000/health

# R√©ponse attendue :
# {"status":"ok"}
```

### Monitoring Continu

**Script** : [`myia_vllm/scripts/monitor_medium.ps1`](myia_vllm/scripts/monitor_medium.ps1)

```powershell
# Monitoring live (logs + ressources)
pwsh -c ".\myia_vllm\scripts\monitor_medium.ps1"
```

**Fonctionnalit√©s** :
- ‚úÖ Surveillance status conteneur toutes les 10s
- ‚úÖ Extraction derniers logs (20 lignes)
- ‚úÖ D√©tection erreurs critiques (ERROR, FATAL, OOM)
- ‚úÖ Timeout configurable (d√©faut 10 min)

### M√©triques GPU

```bash
# Utilisation GPU en temps r√©el
watch -n 2 nvidia-smi

# GPU du conteneur sp√©cifique
docker exec myia_vllm-medium-qwen3 nvidia-smi
```

**Utilisation attendue** :
- GPU 0 et 1 : ~90-95% pendant inf√©rence
- M√©moire : ~12 GiB utilis√©s / 24 GiB par GPU

---

## 6. Troubleshooting D√©ploiement

### Probl√®me : Container ne d√©marre pas

**Sympt√¥mes :** Container en statut `Exited` ou `Restarting`

**Diagnostic :**
```powershell
# Voir logs d'erreur
docker logs myia_vllm-medium-qwen3
```

**Solutions courantes :**

1. **Erreur API Key** : V√©rifier `.env` contient `VLLM_API_KEY_MEDIUM`
   ```powershell
   grep VLLM_API_KEY_MEDIUM myia_vllm/.env
   ```

2. **GPU non disponible** : V√©rifier `nvidia-smi` fonctionne
   ```bash
   docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
   ```

3. **M√©moire insuffisante** : R√©duire `gpu-memory-utilization` √† 0.80
   ```yaml
   # Dans medium.yml
   --gpu-memory-utilization 0.80
   ```

### Probl√®me : Health Check √©choue

**Sympt√¥mes :** Container en statut `(unhealthy)`

**Diagnostic :**
```bash
# Voir d√©tails health check
docker inspect myia_vllm-medium-qwen3 | grep -A 10 Health
```

**Solutions :**
1. Attendre plus longtemps (chargement mod√®le ~5-10 min)
2. V√©rifier logs : `docker logs myia_vllm-medium-qwen3 | tail -50`
3. Chercher "Model loaded successfully" dans les logs

### Probl√®me : API ne r√©pond pas

**Sympt√¥mes :** Container `(healthy)` mais `curl` √©choue

**Diagnostic :**
```bash
# Tester endpoint principal
curl http://localhost:8000/v1/models
```

**Solutions :**
1. V√©rifier port mapping : `docker ps` (doit montrer `0.0.0.0:8000->8000/tcp`)
2. V√©rifier firewall n'bloque pas port 8000
3. Voir section d√©di√©e dans [`TROUBLESHOOTING.md`](myia_vllm/docs/TROUBLESHOOTING.md)

### Probl√®me : GPUs Non D√©tect√©s

**Sympt√¥mes :**
```
RuntimeError: Failed to infer device type
ImportError: libcuda.so.1: cannot open shared object file
```

**Cause Racine** : Configuration Docker Swarm incompatible avec Docker Compose standalone

**Solution** : Utiliser syntaxe Docker Compose correcte dans [`medium.yml`](myia_vllm/configs/docker/profiles/medium.yml)

‚úÖ **CORRECT (Docker Compose standalone)** :
```yaml
runtime: nvidia
ipc: host
shm_size: '16gb'
environment:
  - NVIDIA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES_MEDIUM:-0,1}
```

‚ùå **INCORRECT (Docker Swarm)** :
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          capabilities: [gpu]
```

**Validation du Fix :**
```powershell
# D√©ploiement avec script officiel
pwsh -File scripts/deploy_medium_monitored.ps1

# Le monitoring doit afficher :
# ‚úÖ Automatically detected platform cuda
# ‚úÖ GPU KV cache size: 195,312 tokens
# ‚úÖ Available KV cache memory: 11.92 GiB
# ‚úÖ Status: healthy
```

**üìö Documentation d√©taill√©e** : Voir [`deployment/DEPLOYMENT_SAFETY.md`](myia_vllm/docs/deployment/DEPLOYMENT_SAFETY.md)

---

## 7. Scripts de R√©f√©rence

### Scripts de D√©ploiement

| Script | Fonction | Usage |
|--------|----------|-------|
| [`deploy_medium_monitored.ps1`](myia_vllm/scripts/deploy_medium_monitored.ps1) | D√©ploiement automatis√© | Recommand√© production |
| [`wait_for_container_healthy.ps1`](myia_vllm/scripts/monitoring/wait_for_container_healthy.ps1) | Attente health check | Int√©gration CI/CD |
| [`monitor_medium.ps1`](myia_vllm/scripts/monitor_medium.ps1) | Monitoring continu | Debugging live |

### Scripts de Validation

| Script | Fonction | Usage |
|--------|----------|-------|
| [`mission15_validation_tests.ps1`](myia_vllm/scripts/testing/mission15_validation_tests.ps1) | Suite tests validation | Post-d√©ploiement |
| [`test_kv_cache_acceleration.ps1`](myia_vllm/scripts/test_kv_cache_acceleration.ps1) | Benchmark KV Cache | Performance |
| [`check_ram_usage.ps1`](myia_vllm/scripts/check_ram_usage.ps1) | V√©rification ressources | Pr√©-d√©ploiement |

### Scripts de Maintenance

Voir [`scripts/maintenance/`](myia_vllm/scripts/maintenance/) et guide d√©di√© [`MAINTENANCE_PROCEDURES.md`](myia_vllm/docs/MAINTENANCE_PROCEDURES.md)

---

## üìö Documentation Compl√©mentaire

- **Architecture Docker** : [`docker/ARCHITECTURE.md`](myia_vllm/docs/docker/ARCHITECTURE.md)
- **Param√®tres Service** : [`docker/MEDIUM_SERVICE_PARAMETERS.md`](myia_vllm/docs/docker/MEDIUM_SERVICE_PARAMETERS.md)
- **Configuration `.env`** : [`setup/ENV_CONFIGURATION.md`](myia_vllm/docs/setup/ENV_CONFIGURATION.md)
- **Optimisation Configuration** : [`OPTIMIZATION_GUIDE.md`](myia_vllm/docs/OPTIMIZATION_GUIDE.md)
- **R√©solution Probl√®mes** : [`TROUBLESHOOTING.md`](myia_vllm/docs/TROUBLESHOOTING.md)
- **Rapport D√©ploiement 16/10** : [`deployment/DEPLOYMENT_MEDIUM_20251016.md`](myia_vllm/docs/deployment/DEPLOYMENT_MEDIUM_20251016.md)

---

**Fin du Guide de D√©ploiement vLLM Medium**