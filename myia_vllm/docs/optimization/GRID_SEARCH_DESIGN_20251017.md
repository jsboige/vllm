# Design du Grid Search pour Optimisation Agentique Multi-Tours
## Mission 11 - Phase 4

**Date de Cr√©ation** : 2025-10-17  
**Auteur** : Roo Architect (Mode)  
**Statut** : ‚úÖ Design Valid√© - Pr√™t pour Impl√©mentation

---

## üìã Table des Mati√®res

1. [Contexte et Objectifs](#contexte-et-objectifs)
2. [Analyse des R√©sultats Pr√©c√©dents](#analyse-des-r√©sultats-pr√©c√©dents)
3. [M√©thodologie de S√©lection](#m√©thodologie-de-s√©lection)
4. [Espace de Param√®tres](#espace-de-param√®tres)
5. [Les 12 Configurations Strat√©giques](#les-12-configurations-strat√©giques)
6. [Ordre de Test et Priorit√©s](#ordre-de-test-et-priorit√©s)
7. [M√©triques de Succ√®s](#m√©triques-de-succ√®s)
8. [Hypoth√®ses et Pr√©dictions](#hypoth√®ses-et-pr√©dictions)
9. [Proc√©dure d'Ex√©cution](#proc√©dure-dex√©cution)

---

## üéØ Contexte et Objectifs

### Probl√®me Initial

Les tests pr√©c√©dents ont r√©v√©l√© une **d√©gradation catastrophique des performances** lors de l'activation simultan√©e de `--enable-prefix-caching` et `--enable-chunked-prefill` :

- **Baseline** : TTFT MISS = 1828ms, TTFT HIT = 1607ms
- **Optimisations combin√©es** : TTFT MISS = 4376ms (+139%), TTFT HIT = 3199ms (+99%)

Bien que l'acc√©l√©ration du cache ait augment√© de +20%, la latence absolue est devenue **inacceptable pour une utilisation en production**.

### Objectifs du Grid Search

1. **Isoler les impacts** : Tester `prefix-caching` et `chunked-prefill` **ind√©pendamment**
2. **Optimiser pour agents multi-tours** : Privil√©gier les configurations qui minimisent TTFT HIT (tours N+1)
3. **Trouver le sweet spot** : Configuration avec TTFT < baseline +20% et acc√©l√©ration cache > +50%
4. **Valider la robustesse** : Tester diff√©rentes valeurs de `gpu_memory_utilization`

### D√©cision Strat√©gique : Configuration GPU Actuelle

**Contexte Mat√©riel D√©couvert** :
- 3x RTX 4090 d√©tect√©s (au lieu de 2 attendus)
- GPU 0 et 1 : **PCIe 8x** (50% de bande passante th√©orique vs 16x)
- GPU 2 : PCIe 4x (25% de bande passante)
- Configuration actuelle : `CUDA_VISIBLE_DEVICES_MEDIUM=0,1`

**D√©cision** : Proc√©der avec la configuration mat√©rielle actuelle (PCIe 8x). Les recherches web (Reddit, benchmarks DatabaseMart) confirment que PCIe 8x **ne devrait PAS √™tre un goulot d'√©tranglement** pour vLLM avec 2 GPUs. Approche pragmatique : **optimiser le logiciel d'abord**, investiguer le mat√©riel apr√®s si les r√©sultats sont insatisfaisants.

---

## üìä Analyse des R√©sultats Pr√©c√©dents

### Configuration Baseline (R√©f√©rence)

```yaml
# myia_vllm/configs/docker/profiles/medium.yml
command:
  - "--model"
  - "Qwen/Qwen3-32B-AWQ"
  - "--tensor-parallel-size"
  - "2"
  - "--gpu-memory-utilization"
  - "0.95"
  # Prefix caching: DISABLED (par d√©faut)
  # Chunked prefill: DISABLED (ou d√©faut V1)
```

**M√©triques Baseline** :
- TTFT MISS (premier message) : 1828ms
- TTFT HIT (messages suivants) : 1607ms
- Acc√©l√©ration cache : x1.14 (+12.1%)
- Gain relatif : 12.1%

### Configuration "Optimis√©e" (√âchec Pr√©c√©dent)

```yaml
command:
  - "--model"
  - "Qwen/Qwen3-32B-AWQ"
  - "--tensor-parallel-size"
  - "2"
  - "--gpu-memory-utilization"
  - "0.95"
  - "--enable-prefix-caching"
  - "--enable-chunked-prefill"
  - "--max-num-seqs"
  - "32"
  - "--max-num-batched-tokens"
  - "2048"
```

**M√©triques "Optimis√©es"** :
- TTFT MISS : 4376ms (+139% vs baseline)
- TTFT HIT : 3199ms (+99% vs baseline)
- Acc√©l√©ration cache : x1.37 (+20% vs baseline)
- Gain relatif : 26.9% (+122% vs baseline)

**Analyse** : L'acc√©l√©ration relative du cache a bien augment√©, mais la latence absolue est **2-3x pire** que le baseline. Cette configuration est **inutilisable en production**.

---

## üîç M√©thodologie de S√©lection

### Principe de Design

Au lieu de tester exhaustivement toutes les combinaisons (3√ó2√ó2√ó4√ó4 = **192 configurations**), nous avons s√©lectionn√© **12 configurations strat√©giques** bas√©es sur :

1. **Recherches S√©mantiques SDDD** :
   - Documentation vLLM sur Optimization & Tuning
   - Automatic Prefix Caching (APC)
   - Chunked Prefill et ses param√®tres

2. **Recherches Web SearXNG** :
   - Best practices vLLM pour agents multi-tours
   - Configuration Tensor Parallel pour RTX 4090
   - Benchmarks DatabaseMart et retours Reddit

3. **Hypoth√®ses Scientifiques** :
   - Prefix caching = optimisation id√©ale pour agents (r√©utilisation system prompt + historique)
   - Chunked prefill = potentiellement contre-productif (augmente TTFT)
   - Interaction n√©gative entre les deux m√©canismes

### Cat√©gories de Tests

1. **Baseline + Prefix Caching Isol√©** (4 configs) : Hypoth√®se principale
2. **Chunked Prefill Isol√©** (2 configs) : Compr√©hension de l'impact n√©gatif
3. **Combinaisons Optimis√©es** (3 configs) : Si jamais les deux peuvent coexister
4. **Variations Exp√©rimentales** (3 configs) : Exploration des param√®tres annexes

---

## üéõÔ∏è Espace de Param√®tres

### 1. `gpu_memory_utilization`

**Valeurs test√©es** : [0.90, 0.92, 0.95]

**Rationale** :
- **0.95** : Valeur actuelle (baseline), maximise la m√©moire disponible pour le cache
- **0.92** : Valeur interm√©diaire, √©quilibre cache et stabilit√©
- **0.90** : Valeur minimale recommand√©e, r√©duit les risques d'OOM

**Impact attendu** :
- R√©duire la m√©moire GPU peut am√©liorer la **stabilit√©** en √©vitant les swaps de cache
- Peut l√©g√®rement r√©duire la taille du cache de pr√©fixes, impactant l'acc√©l√©ration

### 2. `enable_prefix_caching`

**Valeurs test√©es** : [false, true]

**Rationale** :
- **false** : Comportement par d√©faut vLLM (pas de r√©utilisation de cache)
- **true** : R√©utilise le KV cache pour les pr√©fixes communs (system prompt, historique)

**Impact attendu** :
- **true** devrait drastiquement r√©duire TTFT HIT (tours N+1) pour les t√¢ches conversationnelles
- Impact minimal sur TTFT MISS (premier tour)
- Consommation m√©moire GPU l√©g√®rement accrue

### 3. `enable_chunked_prefill`

**Valeurs test√©es** : [false, true]

**Rationale** :
- **false** : Traite le prefill en une seule passe (mode traditionnel)
- **true** : D√©coupe le prefill en chunks pour batching avec decode

**Impact attendu** :
- **true** am√©liore le throughput (tokens/sec) mais **augmente TTFT**
- Effet probablement **contre-productif** pour agents multi-tours (latence critique)

### 4. `max_num_seqs`

**Valeurs test√©es** : [null, 32, 64, 128]

**Rationale** :
- **null** : Valeur par d√©faut vLLM (auto-calcul√©e selon mod√®le et m√©moire)
- **32-128** : Nombre de s√©quences trait√©es en parall√®le (impact batching et m√©moire)

**Impact attendu** :
- Valeurs plus √©lev√©es augmentent le throughput mais peuvent impacter TTFT si saturation
- Interaction complexe avec `prefix_caching` (plus de s√©quences = plus de partage de cache)

### 5. `max_num_batched_tokens`

**Valeurs test√©es** : [null, 2048, 4096, 8192]

**Rationale** :
- **null** : Valeur par d√©faut vLLM
- **2048-8192** : Contr√¥le la taille des chunks pour chunked prefill

**Impact attendu** :
- **Documentation officielle** : Valeurs plus √©lev√©es **r√©duisent TTFT** mais diminuent throughput
- Param√®tre critique si chunked prefill est activ√©

---

## üß™ Les 12 Configurations Strat√©giques

### Configuration 1 : `baseline_reference` (Priorit√© 1)

**Description** : Baseline actuelle pour r√©f√©rence (d√©j√† test√©e)

```yaml
gpu_memory: 0.95
prefix_caching: false
chunked_prefill: false
max_num_seqs: null
max_num_batched_tokens: null
```

**Hypoth√®se** : Configuration de r√©f√©rence (TTFT MISS: 1828ms, HIT: 1607ms)

**M√©triques attendues** : Confirmer les valeurs baseline

---

### Configuration 2 : `prefix_only_095` (Priorit√© 2) ‚≠ê

**Description** : Prefix caching seul avec GPU memory 0.95

```yaml
gpu_memory: 0.95
prefix_caching: true
chunked_prefill: false
max_num_seqs: null
max_num_batched_tokens: null
```

**Hypoth√®se** : **Optimisation id√©ale pour multi-tours** - devrait am√©liorer cache HIT sans impacter MISS

**M√©triques attendues** :
- TTFT MISS : ~1800-2000ms (< +10% vs baseline)
- TTFT HIT : ~800-1000ms (-40% √† -50% vs baseline) ‚úÖ
- Acc√©l√©ration cache : x1.8 √† x2.5 (+80% √† +150%)

**Pourquoi c'est probablement la configuration gagnante** :
- Con√ßu explicitement pour t√¢ches conversationnelles
- R√©utilise system prompt + historique √† chaque tour
- Pas d'impact n√©gatif du chunked prefill

---

### Configuration 3 : `prefix_only_092` (Priorit√© 3)

**Description** : Prefix caching seul avec GPU memory r√©duite

```yaml
gpu_memory: 0.92
prefix_caching: true
chunked_prefill: false
max_num_seqs: null
max_num_batched_tokens: null
```

**Hypoth√®se** : R√©duire m√©moire GPU peut am√©liorer stabilit√© du cache

**M√©triques attendues** : Similaires √† config 2, l√©g√®rement moins de capacit√© cache

---

### Configuration 4 : `prefix_only_090` (Priorit√© 4)

**Description** : Prefix caching seul avec GPU memory 0.90

```yaml
gpu_memory: 0.90
prefix_caching: true
chunked_prefill: false
max_num_seqs: null
max_num_batched_tokens: null
```

**Hypoth√®se** : M√©moire minimale recommand√©e avec prefix caching

**M√©triques attendues** : Cache plus petit mais plus stable (moins d'OOM)

---

### Configuration 5 : `chunked_only_default` (Priorit√© 5)

**Description** : Chunked prefill seul avec param√®tres par d√©faut

```yaml
gpu_memory: 0.95
prefix_caching: false
chunked_prefill: true
max_num_seqs: null
max_num_batched_tokens: null
```

**Hypoth√®se** : Test chunked prefill isol√© - devrait augmenter TTFT mais am√©liorer throughput

**M√©triques attendues** :
- TTFT MISS : ~2500-3000ms (+30-60% vs baseline) ‚ö†Ô∏è
- TTFT HIT : ~2200-2700ms (+35-70% vs baseline)
- Throughput : +20-30% vs baseline ‚úÖ

**Objectif** : Quantifier l'impact n√©gatif de chunked prefill sur TTFT

---

### Configuration 6 : `chunked_only_high_tokens` (Priorit√© 6)

**Description** : Chunked prefill avec `max_num_batched_tokens` √©lev√©

```yaml
gpu_memory: 0.95
prefix_caching: false
chunked_prefill: true
max_num_seqs: null
max_num_batched_tokens: 8192
```

**Hypoth√®se** : Augmenter tokens par batch devrait r√©duire TTFT selon doc officielle

**M√©triques attendues** : TTFT meilleur que config 5 mais probablement toujours > baseline

---

### Configuration 7 : `combined_optimized_high_tokens` (Priorit√© 7)

**Description** : Prefix + Chunked avec `max_num_batched_tokens` √©lev√©

```yaml
gpu_memory: 0.92
prefix_caching: true
chunked_prefill: true
max_num_seqs: 64
max_num_batched_tokens: 8192
```

**Hypoth√®se** : Combinaison optimis√©e - tokens √©lev√©s pour r√©duire impact chunked sur TTFT

**M√©triques attendues** : Meilleur que l'√©chec pr√©c√©dent (+139%) mais probablement pas mieux que prefix seul

---

### Configuration 8 : `combined_conservative` (Priorit√© 8)

**Description** : Prefix + Chunked avec param√®tres conservateurs

```yaml
gpu_memory: 0.90
prefix_caching: true
chunked_prefill: true
max_num_seqs: 32
max_num_batched_tokens: 4096
```

**Hypoth√®se** : Approche conservatrice pour √©viter over-subscription m√©moire

**M√©triques attendues** : Plus stable que config 7 mais latence toujours √©lev√©e

---

### Configuration 9 : `prefix_high_seqs` (Priorit√© 9)

**Description** : Prefix caching avec `max_num_seqs` √©lev√©

```yaml
gpu_memory: 0.92
prefix_caching: true
chunked_prefill: false
max_num_seqs: 128
max_num_batched_tokens: null
```

**Hypoth√®se** : Augmenter parall√©lisme sans chunked prefill pour am√©liorer throughput

**M√©triques attendues** : TTFT similaire √† configs 2-4, throughput l√©g√®rement meilleur

---

### Configuration 10 : `chunked_low_memory` (Priorit√© 10)

**Description** : Chunked prefill avec m√©moire GPU r√©duite

```yaml
gpu_memory: 0.90
prefix_caching: false
chunked_prefill: true
max_num_seqs: 64
max_num_batched_tokens: 4096
```

**Hypoth√®se** : Tester si m√©moire r√©duite impacte chunked prefill

**M√©triques attendues** : TTFT √©lev√© comme config 5, stabilit√© accrue

---

### Configuration 11 : `combined_balanced` (Priorit√© 11)

**Description** : Prefix + Chunked avec √©quilibre tokens/seqs

```yaml
gpu_memory: 0.95
prefix_caching: true
chunked_prefill: true
max_num_seqs: 64
max_num_batched_tokens: 4096
```

**Hypoth√®se** : Configuration √©quilibr√©e entre les deux optimisations

**M√©triques attendues** : Compromis entre configs 7 et 8

---

### Configuration 12 : `prefix_only_high_memory_high_seqs` (Priorit√© 12) ‚≠ê

**Description** : Prefix caching agressif avec m√©moire et parall√©lisme √©lev√©s

```yaml
gpu_memory: 0.95
prefix_caching: true
chunked_prefill: false
max_num_seqs: 128
max_num_batched_tokens: null
```

**Hypoth√®se** : Maximiser les b√©n√©fices du prefix caching seul pour agents multi-tours

**M√©triques attendues** : Meilleur throughput que config 2, TTFT similaire

**Configuration alternative gagnante potentielle** : Si throughput est critique

---

## üìê Ordre de Test et Priorit√©s

### Phase 1 : Baseline + Prefix Caching Isol√© (Priorit√© 1-4)

**Objectif** : Valider l'hypoth√®se principale (prefix caching = optimisation id√©ale)

1. **baseline_reference** (config 1) : Confirmer m√©triques de r√©f√©rence
2. **prefix_only_095** (config 2) : ‚≠ê Test de l'hypoth√®se principale
3. **prefix_only_092** (config 3) : Variation m√©moire interm√©diaire
4. **prefix_only_090** (config 4) : Variation m√©moire conservatrice

**D√©cision interm√©diaire** : Si config 2 ou 3 atteint les objectifs (TTFT < +20%, acc√©l√©ration > +50%), on peut **arr√™ter le grid search** et passer directement √† la documentation.

### Phase 2 : Chunked Prefill Isol√© (Priorit√© 5-6)

**Objectif** : Quantifier l'impact n√©gatif de chunked prefill

5. **chunked_only_default** (config 5) : Test avec param√®tres par d√©faut
6. **chunked_only_high_tokens** (config 6) : Test avec param√®tre optimis√©

**D√©cision interm√©diaire** : Si TTFT > +50% vs baseline, confirmer que chunked prefill est contre-productif pour notre cas d'usage.

### Phase 3 : Combinaisons et Variations (Priorit√© 7-12)

**Objectif** : Exploration fine si aucune config pr√©c√©dente n'est satisfaisante

7. **combined_optimized_high_tokens** (config 7)
8. **combined_conservative** (config 8)
9. **prefix_high_seqs** (config 9)
10. **chunked_low_memory** (config 10)
11. **combined_balanced** (config 11)
12. **prefix_only_high_memory_high_seqs** (config 12) : ‚≠ê Alternative

---

## üéØ M√©triques de Succ√®s

Pour chaque configuration, les m√©triques suivantes seront collect√©es :

### M√©triques Primaires (Performance)

1. **TTFT MISS (ms)** : Time To First Token pour le premier message (cache miss)
   - **Objectif** : < baseline +20% (< 2194ms)
   - **Id√©al** : < baseline +10% (< 2011ms)

2. **TTFT HIT (ms)** : Time To First Token pour les messages suivants (cache hit)
   - **Objectif** : < baseline -30% (< 1125ms)
   - **Id√©al** : < baseline -50% (< 804ms)

3. **Acc√©l√©ration Cache (ratio)** : TTFT MISS / TTFT HIT
   - **Objectif** : > x1.5 (+50% vs baseline x1.14)
   - **Id√©al** : > x2.0 (+75% vs baseline)

4. **Gain Relatif (%)** : (TTFT MISS - TTFT HIT) / TTFT MISS
   - **Objectif** : > 30% (vs baseline 12.1%)
   - **Id√©al** : > 50%

5. **Throughput (tokens/sec)** : Pour contexte (non critique pour agents)

### M√©triques Secondaires (Stabilit√©)

6. **Temps d√©marrage container (sec)** : D√©lai avant "healthy"
7. **Erreurs OOM** : Nombre d'erreurs Out Of Memory
8. **Crashes** : Nombre de crashes du container pendant les tests
9. **Timeouts** : Nombre de timeouts de requ√™tes

### Tableau de Synth√®se

```markdown
| Config | GPU Mem | Prefix | Chunked | Seqs | Tokens | TTFT MISS | TTFT HIT | Accel | Gain % | Throughput | OOM | Crashes |
|--------|---------|--------|---------|------|--------|-----------|----------|-------|--------|------------|-----|---------|
| baseline | 0.95 | ‚ùå | ‚ùå | - | - | 1828ms | 1607ms | x1.14 | 12.1% | [data] | 0 | 0 |
| prefix_only_095 | 0.95 | ‚úÖ | ‚ùå | - | - | [data] | [data] | [data] | [data] | [data] | [data] | [data] |
| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |
```

---

## üîÆ Hypoth√®ses et Pr√©dictions

### Hypoth√®se Principale (Haute Confiance)

**`prefix_only_095`** (config 2) ou **`prefix_only_092`** (config 3) sera la **configuration optimale** pour les t√¢ches agentiques multi-tours.

**Justification** :
- Documentation vLLM : Prefix caching con√ßu explicitement pour conversations
- Pas d'impact n√©gatif du chunked prefill (qui augmente TTFT)
- R√©utilisation efficace du system prompt et de l'historique

**Pr√©dictions** :
- TTFT MISS : 1800-2000ms (< +10% vs baseline) ‚úÖ
- TTFT HIT : 800-1000ms (-40% √† -50% vs baseline) ‚úÖ‚úÖ‚úÖ
- Acc√©l√©ration cache : x1.8 √† x2.5 (+80% √† +150%) ‚úÖ‚úÖ
- Gain relatif : 45-55% ‚úÖ‚úÖ

### Hypoth√®se Secondaire (Moyenne Confiance)

**Chunked prefill est contre-productif** pour les agents multi-tours (latence critique).

**Justification** :
- Documentation vLLM : Chunked prefill augmente TTFT (compromis throughput vs latence)
- R√©sultats pr√©c√©dents : +99-139% de latence avec chunked prefill activ√©
- Cas d'usage agentique : Latence > Throughput

**Pr√©dictions** :
- Config 5 (chunked seul) : TTFT MISS +30-60% vs baseline ‚ö†Ô∏è
- Config 6 (chunked + tokens √©lev√©s) : TTFT l√©g√®rement meilleur mais toujours > baseline
- Configs 7-8 (combin√©es) : Impossibles √† optimiser pour atteindre TTFT < +20%

### Hypoth√®se Tertiaire (Faible Confiance)

**R√©duire `gpu_memory_utilization` peut am√©liorer la stabilit√©** sans impacter significativement les performances.

**Justification** :
- √âvite les swaps de cache en cas de pics de demande
- Peut r√©duire l√©g√®rement la taille du cache mais am√©liorer la coh√©rence

**Pr√©dictions** :
- Configs 3-4 (GPU 0.92-0.90) : TTFT similaire √† config 2, moins d'OOM

### Configuration Alternative (Si Throughput Critique)

Si le throughput (tokens/sec) s'av√®re √™tre un goulot d'√©tranglement :

**`prefix_only_high_memory_high_seqs`** (config 12) pourrait √™tre pr√©f√©r√©e :
- TTFT similaire aux configs 2-3
- Throughput sup√©rieur gr√¢ce √† `max_num_seqs=128`

---

## üöÄ Proc√©dure d'Ex√©cution

### Pr√©-requis

1. **Environnement** : Docker Compose configur√© avec `medium.yml`
2. **Scripts de test** :
   - `myia_vllm/scripts/test_kv_cache_acceleration.ps1` : Tests TTFT et cache
   - `myia_vllm/scripts/test_performance_ttft.py` : Tests TTFT d√©taill√©s
   - `myia_vllm/scripts/test_performance_throughput.py` : Tests throughput

3. **Configuration actuelle** : Backup de `medium.yml` avant modifications

### Workflow Automatis√©

Le script `grid_search_optimization.ps1` (Phase 5) g√©rera le workflow complet :

```powershell
# Pour chaque configuration dans le fichier JSON :
ForEach ($config in $configs) {
    # 1. Modifier medium.yml avec les param√®tres de la config
    Update-MediumConfig -Config $config

    # 2. Backup de la config actuelle
    Backup-ConfigFile -Name $config.name

    # 3. Red√©ployer le container
    docker compose -f myia_vllm/configs/docker/profiles/medium.yml down
    docker compose -f myia_vllm/configs/docker/profiles/medium.yml up -d

    # 4. Attendre healthy (timeout 10 min)
    Wait-ContainerHealthy -Timeout 600

    # 5. Ex√©cuter les tests
    & myia_vllm/scripts/test_kv_cache_acceleration.ps1
    python myia_vllm/scripts/test_performance_ttft.py
    python myia_vllm/scripts/test_performance_throughput.py

    # 6. Sauvegarder les r√©sultats
    Save-TestResults -Config $config.name -Output "results_$($config.name).json"

    # 7. Logs et progression
    Write-Progress -Config $config.name -Status "Completed"
}
```

### Gestion des Erreurs

- **Timeout d√©ploiement** : Skip la config apr√®s 10 min, passer √† la suivante
- **Erreurs OOM** : Logger l'erreur, ajouter flag `oom_error=true` dans les r√©sultats
- **Crashes** : Red√©ployer une fois, si √©chec persistant, skip la config
- **Interruption** : Sauvegarder √©tat actuel, permettre reprise depuis la derni√®re config test√©e

### Restauration Baseline

En cas d'interruption ou de probl√®me :

```powershell
# Restaurer la configuration baseline
Restore-ConfigFile -Name "baseline_reference"
docker compose -f myia_vllm/configs/docker/profiles/medium.yml down
docker compose -f myia_vllm/configs/docker/profiles/medium.yml up -d
```

### Dur√©e Estim√©e

- **D√©ploiement + tests** : ~15-20 min par configuration
- **12 configurations** : ~3-4 heures au total
- **Phases 1-2** (configs 1-6) : ~1.5-2 heures (d√©cision interm√©diaire possible)

### Logs et Tra√ßabilit√©

Tous les logs seront sauvegard√©s dans :
```
myia_vllm/logs/grid_search_20251017/
‚îú‚îÄ‚îÄ config_baseline_reference.log
‚îú‚îÄ‚îÄ config_prefix_only_095.log
‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ results_baseline_reference.json
‚îú‚îÄ‚îÄ results_prefix_only_095.json
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ grid_search_summary.json
```

---

## üìö R√©f√©rences

### Recherches S√©mantiques SDDD (Phase 1)

1. **Optimisations vLLM existantes** :
   - `KV_CACHE_OPTIMIZATION_20251016.md` : Documentation des tests pr√©c√©dents
   - `optimization_comparison_20251016.md` : M√©triques baseline vs optimis√©

2. **Architecture actuelle** :
   - `MEDIUM_SERVICE_PARAMETERS.md` : Param√®tres du service medium
   - `medium.yml` : Configuration Docker Compose actuelle

3. **Tests de performance** :
   - `test_kv_cache_acceleration.ps1` : Script de test TTFT et cache
   - `run_all_tests.ps1` : Suite de tests compl√®te

### Recherches Web SearXNG (Phase 2)

1. **Best Practices vLLM** :
   - [vLLM Documentation - Optimization & Tuning](https://docs.vllm.ai/en/stable/usage/optimization.html)
   - [Automatic Prefix Caching (APC)](https://docs.vllm.ai/en/stable/usage/automatic_prefix_caching.html)

2. **Configuration Multi-GPU** :
   - [Reddit - Tensor Parallel PCIe Bandwidth](https://www.reddit.com/r/LocalLLaMA/comments/1m8vqnz/tensor_parallel_pcie_bandwidth_requirement/)
   - [DatabaseMart - vLLM 2√óRTX 4090 Benchmark](https://www.databasemart.com/blog/vllm-gpu-benchmark-dual-rtx4090)
   - [vLLM Distributed Inference Optimization Guide](https://www.databasemart.com/blog/vllm-distributed-inference-optimization-guide)

3. **Configuration GPU** :
   - [vLLM Discussion #691 - Specify GPU](https://github.com/vllm-project/vllm/discussions/691)
   - [Stack Overflow - Multi-GPU vLLM](https://stackoverflow.com/questions/78990683/how-can-run-vllm-model-on-a-multi-gpu-server)

---

## ‚úÖ Validation du Design

Ce design a √©t√© valid√© selon les crit√®res SDDD :

1. ‚úÖ **Grounding s√©mantique initial** : 3 recherches effectu√©es (optimisations, architecture, tests)
2. ‚úÖ **Recherche web SearXNG** : Best practices et configuration multi-GPU valid√©es
3. ‚úÖ **Configuration GPU v√©rifi√©e** : PCIe 8x document√©, d√©cision de proc√©der confirm√©e
4. ‚úÖ **S√©lection intelligente de configurations** : 12 configs strat√©giques (vs 192 exhaustives)
5. ‚úÖ **Hypoth√®ses scientifiques** : Pr√©dictions bas√©es sur documentation officielle et retours terrain
6. ‚úÖ **M√©triques de succ√®s** : Objectifs clairs (TTFT < +20%, acc√©l√©ration > +50%)

**Prochaine √âtape** : Impl√©mentation du script `grid_search_optimization.ps1` (Phase 5 - D√©l√©gation CODE)

---

**Statut du Document** : ‚úÖ Pr√™t pour Impl√©mentation  

---

## ‚ö†Ô∏è Correction Post-Design : Contexte Agentique Max

**Date** : 2025-10-19  
**Type** : Correction Critique  
**Statut** : ‚úÖ Corrig√©

### Probl√®me D√©tect√©

Apr√®s finalisation du design, une erreur majeure a √©t√© identifi√©e dans les configurations du grid search : **5 configurations sur 12 avaient des valeurs `max_num_batched_tokens` trop basses** (4096 ou 8192) pour supporter les t√¢ches agentiques multi-tours n√©cessitant un contexte de 100k+ tokens.

### Analyse de l'Erreur

**Configurations Affect√©es** :
- Config 6 (`chunked_only_high_tokens`) : `max_num_batched_tokens: 8192`
- Config 7 (`combined_optimized_high_tokens`) : `max_num_batched_tokens: 8192`
- Config 8 (`combined_conservative`) : `max_num_batched_tokens: 4096`
- Config 10 (`chunked_low_memory`) : `max_num_batched_tokens: 4096`
- Config 11 (`combined_balanced`) : `max_num_batched_tokens: 4096`

**Contrainte Baseline** :
- Le mod√®le supporte `--max-model-len 131072` (131K tokens)
- Les t√¢ches agentiques multi-tours n√©cessitent un contexte de 100k+ tokens
- Les valeurs hardcod√©es (4K-8K) emp√™chaient vLLM de tirer parti du contexte complet

**Cause Racine** :
- Design initial privil√©giait l'efficacit√© m√©moire sur la capacit√© de contexte
- Hypoth√®se erron√©e que 4K-8K tokens par batch seraient suffisants
- M√©connaissance du comportement par d√©faut de vLLM avec `max_num_batched_tokens: null`

### Correction Appliqu√©e

**Backup Cr√©√©** :
```
grid_search_configs.json.backup_before_context_fix_20251019_195627
```

**Modifications** :
Toutes les 5 configurations affect√©es ont √©t√© mises √† jour :

```json
// AVANT (Config 6 exemple)
{
  "name": "chunked_only_high_tokens",
  "max_num_batched_tokens": 8192,
  "description": "... (8192 tokens par batch)"
}

// APR√àS
{
  "name": "chunked_only_high_tokens",
  "max_num_batched_tokens": null,
  "description": "... (par d√©faut vLLM - 131K pour contexte agentique)"
}
```

**Param√®tres Pr√©serv√©s** :
- ‚úÖ `gpu_memory_utilization` : Inchang√©
- ‚úÖ `enable_prefix_caching` : Inchang√©
- ‚úÖ `enable_chunked_prefill` : Inchang√©
- ‚úÖ `max_num_seqs` : Inchang√©

### Justification Technique

**Pourquoi `null` est la bonne valeur** :

1. **Avec `enable_chunked_prefill = false`** :
   - vLLM utilise `max_model_len` comme valeur par d√©faut (131K tokens)
   - Permet le traitement complet du contexte agentique

2. **Avec `enable_chunked_prefill = true`** :
   - vLLM calcule automatiquement la taille optimale des chunks
   - S'adapte dynamiquement √† la m√©moire GPU disponible
   - Garantit un √©quilibre entre latence et throughput

3. **Flexibilit√© maximale** :
   - Pas de limite artificielle sur le contexte
   - Auto-optimisation selon les ressources disponibles
   - Coh√©rence avec les capacit√©s r√©elles du mod√®le (131K)

### Impact sur les Hypoth√®ses

**Hypoth√®ses Initiales (Maintenant Invalides)** :
- ‚ùå Config 6 : "8192 tokens par batch devrait r√©duire TTFT"
  - **R√©alit√©** : Limitait artificiellement le contexte √† 8K
- ‚ùå Config 7-8 : "Param√®tres optimis√©s pour combinaison prefix + chunked"
  - **R√©alit√©** : Limitation √† 4K-8K emp√™chait tests valides sur longs contextes

**Nouvelles Hypoth√®ses (Post-Correction)** :
- ‚úÖ Toutes les configs supportent maintenant le contexte complet (131K)
- ‚úÖ Configs avec `chunked_prefill = true` + `null` tokens permettent auto-optimisation
- ‚úÖ Tests agentiques multi-tours (100k+ tokens) maintenant possibles sur toutes les configs
- ‚úÖ Comparaison √©quitable entre configurations sans limitation artificielle

### Impact sur les Pr√©dictions

**Configs 6-8, 10-11 (Avant Correction)** :
- ‚ö†Ô∏è Risque d'OOM ou troncature pour conversations longues (>4K-8K tokens)
- ‚ö†Ô∏è Throughput suboptimal (batches trop petits)
- ‚ö†Ô∏è Impossible de tester r√©ellement le contexte agentique max

**Configs 6-8, 10-11 (Apr√®s Correction)** :
- ‚úÖ Support complet du contexte 131K
- ‚úÖ Auto-optimisation vLLM pour taille de batch
- ‚úÖ Tests agentiques multi-tours valides
- ‚úÖ Meilleure chance de d√©couvrir la configuration optimale

### Nouvelle Hypoth√®se √âmergente

**Config 6 (`chunked_only_high_tokens`) avec `null` pourrait √™tre meilleure** :
- Documentation vLLM : Chunked prefill avec tokens √©lev√©s r√©duit TTFT
- Avec `null`, vLLM choisit automatiquement la taille optimale de chunks
- **Nouvelle pr√©diction** : Config 6 pourrait rivaliser avec configs prefix-only (2-4)

### Validation Post-Correction

- ‚úÖ JSON syntax valid√©e (Python parser)
- ‚úÖ Toutes les 12 configs supportent 100k+ tokens
- ‚úÖ Backup cr√©√© avec succ√®s
- ‚úÖ File encoding : UTF-8
- ‚úÖ Documentation mise √† jour (`grid_search_execution_20251018.md`)

### Le√ßons Apprises

1. **Toujours v√©rifier la coh√©rence avec les capacit√©s r√©elles du mod√®le**
   - `--max-model-len 131072` √©tait la baseline critique
   - Hardcoder `max_num_batched_tokens` √† 4K-8K √©tait incoh√©rent

2. **Comprendre les valeurs par d√©faut de vLLM avant de les overrider**
   - `null` n'est pas une valeur "vide" mais une directive d'auto-optimisation
   - vLLM a des heuristiques sophistiqu√©es pour ces param√®tres

3. **Valider les configurations avec les use cases r√©els**
   - T√¢ches agentiques multi-tours = contexte 100k+ obligatoire
   - Toute limitation artificielle fausse les r√©sultats du grid search

### Recommandation pour l'Ex√©cution

**Proc√©der avec le grid search corrig√©** :
- Les 12 configurations sont maintenant coh√©rentes avec le contexte agentique
- L'hypoth√®se principale (prefix_only_095) reste valide
- Les configurations chunked (5-11) ont maintenant une chance √©quitable
- R√©sultats attendus plus fiables et exploitables

---

**Timestamp Correction** : 2025-10-19T19:59:00Z  
**Status Post-Correction** : ‚úÖ Pr√™t pour Production Launch #3 (CONFIGURATIONS VALID√âES)
**Derni√®re Mise √† Jour** : 2025-10-17T21:48:00Z