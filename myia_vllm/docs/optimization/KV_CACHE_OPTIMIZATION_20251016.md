# Optimisations KV Cache - 16 Octobre 2025

## Changements Appliqu√©s

### 1. Activation Prefix Caching
**Param√®tre** : `--enable-prefix-caching`  
**Objectif** : Acc√©l√©rer les conversations multi-tours en r√©utilisant les prefixes communs  
**Gain attendu** : x2-3 sur TTFT pour messages suivants dans une conversation  
**Documentation** : Ce param√®tre permet de r√©utiliser les tokens de contexte communs entre plusieurs requ√™tes, √©vitant ainsi de recalculer les KV cache pour les parties de prompt identiques.

### 2. Activation Chunked Prefill  
**Param√®tre** : `--enable-chunked-prefill`  
**Objectif** : Meilleur pipeline prefill/decode  
**Gain attendu** : R√©duction latence, meilleur throughput  
**Documentation** : Le chunked prefill d√©coupe le traitement du prompt en chunks plus petits, permettant un meilleur entrelacement avec les op√©rations de decode et une latence r√©duite.

### 3. Correction Syntaxe KV Cache
**Avant** : `--kv_cache_dtype fp8` (underscore)  
**Apr√®s** : `--kv-cache-dtype fp8` (tiret)  
**Objectif** : Conformit√© avec la syntaxe standard vLLM  
**Impact** : Assure que le param√®tre est correctement reconnu par vLLM

### 4. Correction Tool Call Parser
**Avant** : `--tool-call-parser hermes`  
**Apr√®s** : `--tool-call-parser qwen3`  
**Objectif** : Utiliser le parser natif pour Qwen3  
**Impact** : Meilleure compatibilit√© et performances avec le mod√®le Qwen3-32B

### 5. GPU Memory Utilization
**Configuration actuelle** : `--gpu-memory-utilization 0.95` (95%)  
**Statut** : ‚úÖ D√©j√† optimal  
**M√©moire KV Cache** : ~12.58 GiB par GPU (25.16 GiB total)

---

## Configuration D√©taill√©e

### Fichier Modifi√©
`myia_vllm/configs/docker/profiles/medium.yml`

### Diff des Changements
```diff
- --kv_cache_dtype fp8
- --tool-call-parser hermes
+ --kv-cache-dtype fp8
+ --enable-prefix-caching
+ --enable-chunked-prefill
+ --tool-call-parser qwen3
```

---

## M√©triques Avant Optimisation

### Tests KV Cache (17:27:12 - 16/10/2025)

| Test | M√©trique | Valeur |
|------|----------|--------|
| **Conversation Continue** | Premier message (CACHE MISS) | 1828.33ms |
| | Messages suivants (CACHE HIT) | 1606.56ms |
| | üöÄ Acc√©l√©ration | **x1.14** |
| | Gain de performance | 12.1% |
| **Prefill Cache** | Premier message (CACHE MISS) | 1946ms |
| | Messages suivants (CACHE HIT) | 1624.71ms |
| | üöÄ Acc√©l√©ration | **x1.20** |
| | Gain de performance | 16.5% |
| **Messages Ind√©pendants** | TTFT moyen | 1657.11ms |

### Analyse
‚ùå **Performance FAIBLE** - L'acc√©l√©ration du cache √©tait seulement x1.14, bien en-dessous de l'attendu (x2-3).

**Causes probables** :
- Prefix caching non activ√©
- Syntaxe KV cache incorrecte (underscore vs tiret)
- Parser non optimal (hermes vs qwen3)

---

## M√©triques Cibles Apr√®s Optimisation

| M√©trique | Avant | Cible | Am√©lioration Vis√©e |
|----------|-------|-------|-------------------|
| TTFT premier message | 1828ms | <1500ms | -18% |
| TTFT messages suivants | 1606ms | <800ms | -50% |
| Acc√©l√©ration cache conversation | x1.14 | **x2.0+** | +75% |
| Acc√©l√©ration cache prefill | x1.20 | **x2.5+** | +108% |

---

## Proc√©dure de Validation

### √âtapes
1. ‚úÖ Backup configuration actuelle
2. ‚úÖ Application des optimisations
3. ‚è≥ Red√©ploiement avec monitoring
4. ‚è≥ Ex√©cution des tests de validation
5. ‚è≥ Analyse comparative
6. ‚è≥ Rapport final

### Tests √† Ex√©cuter
- `test_kv_cache_acceleration.ps1` - Tests KV cache complets
- `test_performance_ttft.py` - TTFT (5 essais)
- `test_performance_throughput.py` - Throughput
- `test_performance_concurrent.py` - Charge concurrente

---

## Notes Techniques

### Prefix Caching
Le prefix caching est particuli√®rement efficace pour :
- Conversations multi-tours avec contexte commun
- Prompts syst√®me r√©p√©t√©s
- Instructions de base identiques

### Chunked Prefill
Le chunked prefill am√©liore :
- La latence per√ßue (premier token arrive plus vite)
- Le throughput global
- La gestion de la m√©moire

### Risques
- **M√©moire** : Prefix caching n√©cessite plus de m√©moire KV cache
- **Compatibilit√©** : V√©rifier logs pour confirmer activation
- **Stabilit√©** : Monitorer le service apr√®s d√©ploiement

---

## R√©f√©rences

- [vLLM Prefix Caching Documentation](https://docs.vllm.ai/en/latest/performance/caching.html)
- [vLLM Chunked Prefill](https://docs.vllm.ai/en/latest/performance/chunked_prefill.html)
- Configuration backup : `medium.yml.backup_before_optimization`
- Tests backup : `kv_cache_test_BEFORE_optimization.md`

---

**Statut** : üöß En cours de validation  
**Auteur** : Roo Code  
**Date** : 16 octobre 2025