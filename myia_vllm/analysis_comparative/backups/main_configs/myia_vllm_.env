# Token Hugging Face (requis pour accéder aux modèles)
# ⚠️ SECURITY: Token compromis lors attaque APT étatique (mai-juillet 2025)
# TODO: Remplacer par nouveau token HuggingFace après révocation du token compromis
HUGGING_FACE_HUB_TOKEN=YOUR_SECURE_HUGGINGFACE_TOKEN_HERE

# Clés API pour les différents services
VLLM_API_KEY_MICRO=4S985NRGNN0FZ1P6ZZWNHPJOSAJIMD7M
VLLM_API_KEY_MINI=9OYJNTEAAANJF6F17FMHR51Y0532O9QY
VLLM_API_KEY_MEDIUM=Y7PSM158SR952HCAARSLQ344RRPJTDI3

# Ports pour les différents services
VLLM_PORT_MICRO=5000
VLLM_PORT_MINI=5001
VLLM_PORT_MEDIUM=5002

# Url Externe API OpenAI Compatible VLLM 

VLLM_URL_MICRO= https://api.micro.text-generation-webui.myia.io/
VLLM_URL_MINI= https://api.mini.text-generation-webui.myia.io/
VLLM_URL_MEDIUM= https://api.medium.text-generation-webui.myia.io/

# Chemin vers le cache Hugging Face
HF_CACHE_PATH=\\wsl.localhost\Ubuntu\home\user\vllm\.cache\huggingface\hub

# Fuseau horaire
TZ=Europe/Paris


# Configuration des GPU pour les services
CUDA_VISIBLE_DEVICES_MICRO=2
CUDA_VISIBLE_DEVICES_MINI=2
CUDA_VISIBLE_DEVICES_MEDIUM=0,1

# Modèles par défaut pour les services
VLLM_MODEL_MICRO=Orion-zhen/Qwen3-1.7B-AWQ
VLLM_MODEL_MINI=Qwen/Qwen/Qwen3-8B-AWQ
VLLM_MODEL_MEDIUM=Qwen/Qwen3-32B-AWQ


# Optimisations de performance
OMP_NUM_THREADS=1
