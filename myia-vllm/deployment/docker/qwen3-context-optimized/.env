# Configuration des variables d'environnement pour les modèles Qwen3 avec contexte optimisé

# Configuration des ports
VLLM_PORT_QWEN3_32B=5001
VLLM_PORT_QWEN3_8B=5002
VLLM_PORT_QWEN3_MICRO=5003

# Configuration des GPUs
# Utilisez les indices des GPUs séparés par des virgules
CUDA_VISIBLE_DEVICES_QWEN3_32B=0,1  # Utilise les GPUs 0 et 1 pour le modèle 32B
CUDA_VISIBLE_DEVICES_QWEN3_8B=2     # Utilise la GPU 2 pour le modèle 8B
CUDA_VISIBLE_DEVICES_QWEN3_MICRO=2  # Utilise la GPU 2 pour le modèle Micro (partagée avec 8B)

# Utilisation de la mémoire GPU (valeurs entre 0.0 et 1.0)
GPU_MEMORY_UTILIZATION_QWEN3_32B=0.98  # 98% pour le modèle 32B
GPU_MEMORY_UTILIZATION_QWEN3_8B=0.85   # 85% pour le modèle 8B
GPU_MEMORY_UTILIZATION_QWEN3_MICRO=0.12 # 12% pour le modèle Micro

# Clés API (utilisation des clés par défaut des fichiers docker-compose.yml)
VLLM_API_KEY_QWEN3_32B=X0EC4YYP068CPD5TGARP9VQB5U4MAGHY
VLLM_API_KEY_QWEN3_8B=2NEQLFX1OONFHLFCMMW9U7L15DOC9ECB
VLLM_API_KEY_QWEN3_MICRO=LFXNQWMVP9OONFH1O7L15DOC9ECBEC2B

# Token Hugging Face (utilisation de la valeur par défaut des fichiers docker-compose.yml)
HUGGING_FACE_HUB_TOKEN=YOUR_HUGGING_FACE_TOKEN_HERE

# Backend d'attention (FLASHINFER est recommandé pour les longs contextes)
VLLM_ATTENTION_BACKEND=FLASHINFER

# Fuseau horaire
TZ=Europe/Paris

# Désactivation de la communication P2P NCCL (peut aider en cas de problèmes multi-GPU)
NCCL_P2P_DISABLE=1